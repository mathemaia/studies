{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 16:11:00.828717: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-01 16:11:01.138432: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-01 16:11:01.138484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-01 16:11:01.140465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-01 16:11:01.258932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-01 16:11:03.523721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Add\n",
    "import os\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image)\n",
    "    image = tf.image.resize(image, (94, 94))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (94, 94, 3)\n",
    "latent_dim = 32\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=input_shape),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((3, 3), padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((3, 3), padding='same'),\n",
    "            layers.Flatten()\n",
    "        ])\n",
    "        self.mean = layers.Dense(latent_dim)\n",
    "        self.log_var = layers.Dense(latent_dim)\n",
    "    \n",
    "    def call(self, X):\n",
    "        X = self.encoder(X)\n",
    "        return self.mean(X), self.log_var(X)\n",
    "\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(1, latent_dim)),\n",
    "            layers.Dense(7 * 7 * 64, activation='relu'),\n",
    "            layers.Reshape((7, 7, 64)),\n",
    "            layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.decoder(X)\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def call(self, X):\n",
    "        mu, sigma = self.encoder(X)\n",
    "        epsilon = tf.random.normal(tf.shape(mu))\n",
    "        z = tf.expand_dims(mu + epsilon * sigma, axis=0)\n",
    "        X_reconstructed = self.decoder(z)\n",
    "\n",
    "        return X_reconstructed, mu, sigma\n",
    "\n",
    "path = '../data/'\n",
    "images = os.listdir(path)\n",
    "image = load_image(path + images[1])\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "model = VAE(latent_dim)\n",
    "output = (model(image)[0] * 255.0).numpy().astype(int)\n",
    "\n",
    "print(output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 512, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = (94, 94, 3)\n",
    "latent_dim = 32\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=input_shape),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim*2, activation='selu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(1024, activation='selu', input_shape=(latent_dim,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(187392, activation='selu'),\n",
    "            layers.Reshape((61, 256, 10)),\n",
    "            layers.Conv2DTranspose(256, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(128, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(64, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(32, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(3, (5, 5), activation='sigmoid', strides=1, padding='same'),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, X):\n",
    "        mu, sigma = tf.split(self.encoder(X), num_or_size_splits=2, axis=-1)\n",
    "        epsilon = tf.random.normal(tf.shape(sigma))\n",
    "        z = mu + epsilon * tf.exp(0.5 * sigma)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "\n",
    "path = '../data/'\n",
    "images = os.listdir(path)\n",
    "image = load_image(path + images[1])\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "model = VAE(latent_dim)\n",
    "output = (model(image)[0] * 255.0).numpy().astype(int)\n",
    "\n",
    "print(output.shape)\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for image in images:\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed = model(path + image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
