{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 14:30:49.514238: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-09 14:30:49.800767: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 14:30:49.800809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 14:30:49.801970: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 14:30:49.918143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 14:30:51.156264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Add\n",
    "import os\n",
    "from keras.layers import LeakyReLU\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, (64, 64))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.reshape(image, shape=(64, 64, 3))\n",
    "    #image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    return image\n",
    "\n",
    "path = '../data/'\n",
    "images = [os.path.join(path, image) for image in os.listdir(path)]\n",
    "\n",
    "batch_size = 125\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "dataset = dataset.map(load_image)\n",
    "dataset = dataset.shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'encoder' (type Encoder).\n\nInput 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 94, 94, 3), found shape=(64, 64, 3)\n\nCall arguments received by layer 'encoder' (type Encoder):\n  • X=tf.Tensor(shape=(64, 64, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m latent_dim \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model \u001b[39m=\u001b[39m VAE(latent_dim)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m output \u001b[39m=\u001b[39m (model(image)[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m255.0\u001b[39m)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/machinelearning/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     mu, sigma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     epsilon \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(tf\u001b[39m.\u001b[39mshape(mu))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     z \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(mu \u001b[39m+\u001b[39m epsilon \u001b[39m*\u001b[39m sigma, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_var(X)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'encoder' (type Encoder).\n\nInput 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 94, 94, 3), found shape=(64, 64, 3)\n\nCall arguments received by layer 'encoder' (type Encoder):\n  • X=tf.Tensor(shape=(64, 64, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "input_shape = (94, 94, 3)\n",
    "latent_dim = 32\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=input_shape),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((3, 3), padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((3, 3), padding='same'),\n",
    "            layers.Flatten()\n",
    "        ])\n",
    "        self.mean = layers.Dense(latent_dim)\n",
    "        self.log_var = layers.Dense(latent_dim)\n",
    "    \n",
    "    def call(self, X):\n",
    "        X = self.encoder(X)\n",
    "        return self.mean(X), self.log_var(X)\n",
    "\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(1, latent_dim)),\n",
    "            layers.Dense(7 * 7 * 64, activation='relu'),\n",
    "            layers.Reshape((7, 7, 64)),\n",
    "            layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.decoder(X)\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def call(self, X):\n",
    "        mu, sigma = self.encoder(X)\n",
    "        epsilon = tf.random.normal(tf.shape(mu))\n",
    "        z = tf.expand_dims(mu + epsilon * sigma, axis=0)\n",
    "        X_reconstructed = self.decoder(z)\n",
    "\n",
    "        return X_reconstructed, mu, sigma\n",
    "\n",
    "path = '../data/'\n",
    "images = os.listdir(path)\n",
    "image = load_image(path + images[1])\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "model = VAE(latent_dim)\n",
    "output = (model(image)[0] * 255.0).numpy().astype(int)\n",
    "\n",
    "print(output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer((368, 640, 3)),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim*2, activation='selu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(1024, activation='selu', input_shape=(latent_dim,)),\n",
    "            layers.Dense(23 * 40 * 512, activation='selu'),\n",
    "            layers.Reshape((23, 40, 512)),\n",
    "            layers.Conv2DTranspose(256, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(128, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(64, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(32, (5, 5), activation=LeakyReLU(0.02), strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(3, (5, 5), activation='sigmoid', strides=1, padding='same'),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        mu, sigma = tf.split(encoded, num_or_size_splits=2, axis=-1)\n",
    "        epsilon = tf.random.normal(tf.shape(sigma))\n",
    "        z = mu + epsilon * tf.exp(0.5 * sigma)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "model = VAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'vae_1' (type VAE).\n\nInput 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 368, 640, 3), found shape=(368, 640, 3)\n\nCall arguments received by layer 'vae_1' (type VAE):\n  • X=tf.Tensor(shape=(368, 640, 3), dtype=uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m./eucalipto.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model(image)\n",
      "File \u001b[0;32m~/.conda/envs/machinelearning/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     mu, sigma \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(X), num_or_size_splits\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     epsilon \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(tf\u001b[39m.\u001b[39mshape(sigma))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matheusmaia/Github/studies/Python/MachineLearning/UnsupervisedLearning/autoencoders/VAE/model2.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     z \u001b[39m=\u001b[39m mu \u001b[39m+\u001b[39m epsilon \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mexp(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m sigma)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'vae_1' (type VAE).\n\nInput 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 368, 640, 3), found shape=(368, 640, 3)\n\nCall arguments received by layer 'vae_1' (type VAE):\n  • X=tf.Tensor(shape=(368, 640, 3), dtype=uint8)"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./eucalipto.png')\n",
    "\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(y, pred):\n",
    "    return tf.reduce_mean(tf.square(y - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.096620776, shape=(), dtype=float32)\n",
      "tf.Tensor(0.094599545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09532998, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09585252, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:05<00:10,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.097649045, shape=(), dtype=float32)\n",
      "tf.Tensor(0.094190575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09459026, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:07<00:03,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.09597202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.096577436, shape=(), dtype=float32)\n",
      "tf.Tensor(0.095426545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.095999196, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.09440139, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse_losses = []\n",
    "\n",
    "# 368x640\n",
    "\n",
    "for epoch in tqdm(range(3)):\n",
    "    for batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = tf.reshape(model(batch), shape=[-1])\n",
    "            y = tf.reshape(batch, shape=[-1])\n",
    "\n",
    "            mse = reconstruction_loss(y, pred)\n",
    "            mse_losses.append(mse.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
